<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta name="keywords" content="Yu(Jaray) Li, WHU" />
<meta name="description" content="Jaray Li's Homepage" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="img/intro/whu_logo.png" />
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="css/jemdoc_yuzhe.css" type="text/css" />
<link rel="stylesheet" href="ccs/myMiddle.css" type="text/css" />
<title>Yu Li - ECE @ WHU</title>
</head>
<body>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="img/intro/YuLi_mid.jpg" alt="" width="240px" height="Yu Li" />&nbsp;</td>
<td align="left"><h1>Yu(Jaray) Li <span style="font-family: KaiTi;">李煜</span></h1>
<p><b>Senior Student</b> <br />
<a href="https://hyxt.whu.edu.cn/">Hongyi Honor College</a> <br />
<a href="https://en.whu.edu.cn/">Wuhan University</a> <br />

<b>Email</b>:yul79@uci.edu / yuuli2021@whu.edu.cn<br /></p>
<p>
  [<a href="https://github.com/skylanding" target="_blank" class="links">Github</a>]
  [<a href="https://www.linkedin.com/in/yu-li-a089a6282/" target="_blank" class="links">Linkedin</a>]
  [<a href="CV_Yu_Li.pdf" target="_blank" class="links">CV</a>]
  [<a href="Transcripts.pdf" target="_blank" class="links">Transcripts</a>]
</p>

</td></tr></table>
<h2>Biography</h2>
<p>I am currently a senior in <a href="https://hyxt.whu.edu.cn/">Hongyi Honor College</a> of <a href="https://en.whu.edu.cn/">Wuhan University</a>, majoring in Microelectronics Science and Engineering.
I have a certain understanding of digital/analog circuits and computer architecture. My current main research direction is the application of AI in vision, including LLM/VLM research.<br /> </p>
<h2>Recent News</h2>
<div class="infoblock">
<div class="blockcontent">
<ul>
<li><p>[08/2024] I am looking for a PhD position for Fall 2025, hoping to continue exploring practical applications of ML and VLM and on-device deployment.</p>
</li>
<li><p>[08/2024] Our independent research on methods for fine-tuning LLM parameters in OCR methods was accepted by <b>ICONIP 2024</b>.</p>
</li>
<li><p>[05/2024] I will join <a href="https://aicps.eng.uci.edu/"><b>AICPS</b></a> at UC Irvine as a research intern, during summer 2024.</p>
</li>
<li><p>[05/2024] I was awarded the <a href="https://edf.whu.edu.cn/chf/zzxm/yngjjljxj/xmjs.htm">Innova International Exchange Scholarship</a>, thanks to Dr. Charles Huang and Charles Huang Foundation!</p>
</li>
</ul>
</div></div>


<h2>Research</h2>
<p>
  My research focuses on ML&AI application, including improvement of LVLM/VLM, application in medical/healthcare field and integration with EDA.
</p>

<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%;">
            <img src="img/project/chip.jpg" width="250" height="180" alt="Graduation Design"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%;">
            <p>
              Chip placement method based on visual representation and reinforcement learning
              <br>
              <b>Yu Li</b>
              <br/>
              2024.10-Present
              <br/>
<!--               [<a href="https://github.com/Skylanding/SensorFusion">Github</a>] -->
              <br>
              The EDA project is the topic of my graduation project in Wuhan University and I intend to make progress in the automatic chip layout method. The main methods used are reinforcement learning and LLM agent.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

  
<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%;">
            <img src="img/project/UCI_fusion.png" width="250" height="180" alt="UCI Fusion Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%;">
            <p>
              Sensor Fusion for Robust and Efficient Autonomous Vehicle Perception
              <br>
              <b>Yu Li</b>, Junyao Wang
              <br/>
              2024.6-2024.10
              <br/>
              Submitted to <em>CVPR 2025</em>
              <br/>
              [<a href="https://github.com/Skylanding/SensorFusion">Github</a>]
              <br>
              <br>
              Our main work is to construct our VLM to improve the autonomous driving mode in abnormal weather conditions, focusing on improving the multi-modal fusion algorithm of Camera-Lidar branches.
              Hopefully it will be advanced to hardware deployment in the future.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

    
<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Ultrasound.jpg" width="250" height="180" alt="Ultrasound Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
              <papertitle>
              Ultrasound image segmentation based on SAM and Transformer multi-level feature fusion
              </papertitle>
              <!-- </a> -->
              <br />
              <b>Yu Li</b>, Jin Huang
              <br />
              2023.10-2024.5
              <br />
              Conditioanl Accept, <em>Medical Physics</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding/DSATNet">Code</a>]
            </div>
            <br>
            <p>
              We leveraged the rich semantic segmentation information of SAM and 
              applied its fine-grained attention capability to the feature extraction module of Transformer, 
              achieving SOTA IoU scores in ultrasound image segmentation.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Ultrasound2.jpg" width="250" height="180" alt="Ultrasound Image 2"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
                <papertitle>
                  Windowed self-attention guided multi-scale feature stream alignment network for ultrasound image segmentation
                </papertitle>
              <!-- </a> -->
              <br />
              Jin Huang, Xiaoxiao Li, <strong>Yu Li</strong>
              <br />
              2023.9-2024.5
              <br />
              Under Review, <em>Biomedical Signal Processing and Control.</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding">Code</a>]
            </div>
            <br>
            <p>
              We explored the self-attention guidance mechanism of the Swin-Transformer structure in breast ultrasound images, 
              used a multi-level encoder to deal with multi-dimensional features, 
              and used spatial pyramid pooling and feature stream alignment to fuse shallow and deep information.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Depth.jpg" width="250" height="180" alt="Depth Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
                <papertitle>
                  Diffusion model with discriminative priors: Self-supervised monocular depth estimation in endoscopy
                </papertitle>
              <!-- </a> -->
              <br />
              <strong>Yu Li</strong>
              <br />
              2024.2-2024.6
              <br />
              Major Revision, <em> International Journal of Computer Assisted Radiology and Surgery.</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding">Code</a>]
            </div>
            <br>
            <p>
            For endoscope medical scenarios, we use the diffusion model for depth estimation. We build a teacher model, set knowledge distillation, 
            optical appearance and ddim losses, and introduce the teacher's discriminative prior, which significantly enhances the accuracy and confidence of the results.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Monte.png" width="250" height="180" alt="Monte Carlo Simulation Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
                <papertitle>
                SpO2 measurement model based on Monte Carlo simulation
                </papertitle>
              <!-- </a> -->
              <br />
              <strong>Yu Li</strong>, Shing-jiuan Liu, Prof. Weijian Yang
              <br />
              2023.7-2024.5
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding/oximetrey-model">Code</a>]
            </div>
            <br>
            <p>
            We used the modified Beer-Lambert law for reverse deduction, used Monte Carlo simulation data to improve the SpO2 measurement process model and design algorithms, 
            and finally realized the reverse model for determining physiological parameters from simulation data.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/ECG.jpg" width="250" height="180" alt="ECG Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <papertitle>
              ECG classification based on deep learning
              </papertitle>
              <br />
              <strong>Yu Li</strong>, Yunhao Hu
              <br />
              2022.10-2023.3
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://ieeexplore.ieee.org/abstract/document/10335476?casa_token=W35SppfudKkAAAAA:7FrTtfe0OgPMGoRX79ruUt9Ryqpa2Bqnpm2rnvq5MJzDpCw7z8bd9Gfww7SCVQBLez37qyKiYDY">Paper</a>]
            [<a href="https://github.com/Skylanding/ECG-Classification">Code</a>]
            </div>
            <br>
            <p>
              For the attempt of deep learning method for ECG classification, 
              the construction of multi-layer neural network and the parameter grid search of effective tool XGBoost.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<h3>Projects</h3>
<p>
  Individual or Collaborative Projects
</p>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: top">
        <img src="img/project/Dlora.png" width="250" height="180" alt="DLoRA module"/>
      </td>
      <td class="tdcontent" style="padding: 20px; width: 65%; vertical-align: top">
        <p>
          <a href="https://arxiv.org/abs/2404.12734">
            <papertitle>
              <b>DLoRA-TrOCR: Mixed Text Mode Optical Character Recognition Based On Transformer.</b>
            </papertitle>
          </a>
          <br />
          <b>Yu Li</b> & Da Chang</a>
          <br />
          2024.4, <em>ICONIP 2024</em>.
        </p>
        <div class="paper" id="xu2020batchnorm">
          [<a href="https://arxiv.org/abs/2404.12734">Paper</a>]
          [<a href="https://github.com/VceChang/DLoRA-TrOCR">Code</a>]
        </div>
        <br>
        We explored the optimization of various full-parameter fine-tuning methods such as LoRA in LLM. For OCR, a hybrid visual-text model, corresponding to the Transformer architecture, DoRA and LoRA have good improvement effects on the visual encoder and text decoder respectively.
        </p>
      </td>
    </tr>
    
    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
        <img src="img/project/EECS151.png" width="250" height="180" alt="UCB eecs151 aisc"/>
      </td>
      <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: top">
        <p>
          <a href="https://github.com/Skylanding/EECS151-Project">
            <papertitle>
              <b>A 3-stage CPU that implements the RISC-V ISA.</b> [UCB EECS151 Project]
            </papertitle>
          </a>
          <br />
          <b>Yu Li</b>, Timonty Chu
          <br />
          2024.2-2024.4
          <br />
        </p>
        <div class="paper" id="xu2020batchnorm">
          [<a href="https://github.com/EECS150/asic-project-sp24">Asic Lab</a>]
          [<a href="data/pdf/riscv-spec-20191213.pdf">Manual</a>]
          [<a href="https://github.com/Skylanding/EECS151-Project">Project</a>]
        </div>
        <br>
        <p>
          In the first phase (front-end), I design and implement a 3-stage RISC-V processor in Verilog, 
          and run simulations to test for functionality.
          Then in the second phase (back-end), I implement front-end design in the SKY130 PDK using the VLSI tools.
        </p>
      </td>
    </tr>

    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
        <img src="img/project/EE140.png" width="250" height="180" alt="UCB ee140 project"/>
      </td>
      <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
        <p>
          <a href="https://github.com/Skylanding/2024_spring_ee140">
          <papertitle>
          <b>LCD Driver Design: 2-Stage Operational Amplifier. </b> [UCB EE140 Project] 
          </papertitle>
          </a>
          <br />
          <b>Yu Li</b>
          <br />
          2024.2-2024.4
          <br />
        </p>
        <div class="paper" id="xu2020batchnorm">
        [<a href="https://github.com/Skylanding/24-spring-ee140/blob/main/lab/project/LCD%20Driver%20Project.pdf">Project</a>]
        [<a href="data/pdf/EE140_project.pdf">Report</a>]
        </div>
        <br>
        <p>
          To use a series resistance of 400 Ohms and a capacitance of 60 pF to design the LCD amplifier to the specifications.
        </p>
      </td>
    </tr>

    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
        <img src="img/project/Unisoc.png" width="250" height="180" alt="Unisoc Competition"/>
      </td>
      <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
        <p>
          <!-- <a href="https://github.com/Skylanding/EECS151-Project"> -->
            <papertitle>
              FPGA-based video acquisition and performance acceleration
            </papertitle>
          <!-- </a> -->
          <br />
          <b>Yu Li</b>
          <br />
          2023.3-2023.6
          <br />
        </p>
        <div class="paper" id="xu2020batchnorm">
        [<a href="http://univ.ciciec.com/nd.jsp?id=556">Competition Link</a>]
        </div>
        <br>
        <p>
        We developed a multi-channel video acquisition system with hardware acceleration on the Unisoc FPGA. 
        We configured the YoLoV5 model on the host computer, collected video input via HDMI transmission, onboard DDR video frame buffer, and output via PCIE.
        The FPGA acceleration was achieved using several techniques: 
        1) optimized precision conversion, 
        2) pipeline strategy, 
        3) multi-channel and addition structure, 
        and 4) DDR5 partition data sharing.
        </p>
      </td>
    </tr>
  </tbody>
</table>


<h2>Education</h2>
<ul>
<!-- <li><p>Ph.D., Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK), Aug/2023 - Now</p>
</li> -->
<li><p>B.Eng., Hongyi Honor College, Wuhan University, Aug/2021 - Jun/2025</p>
</li>
</ul>
<h2>Experience</h2>
<ul>
  <li><b><a href="https://aicps.eng.uci.edu/">Research Intern</a></b>, UC Irvine, Summer 2024.</li>
</ul>
<ul>
  <li><b><a href="https://eecs.berkeley.edu/">Visiting Student</a></b>, UC Berkeley, Spring 2024.</li>
</ul>
<ul>
  <li><b><a href="https://www.ece.ucdavis.edu/~wejyang/home.html">Research Intern</a></b>, UC Davis, 2023-2024.</li>
</ul>
<ul>
  <li><b><a href="http://www.lei-whu.com/">Research Assistant</a></b>, WHU, 2022-2024.</li>
</ul>
<h2>Honors and Awards</h2>
<table id="noborder">
  <tr class="r1">
    <td class="c1">Innova International Exchange Scholarship,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2024</td>
  </tr>
  <tr class="r2">
    <td class="c1">Innova Excellence Scholarship <span class="small-text">(Top 3%)</span>,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2023,2024</td>
  </tr>
  <tr class="r1">
    <td class="c1">Academic Excellence Scholarship <span class="small-text">(Top 5%)</span>,</td>
    <td class="c2">Hongyi Honor College,</td>
    <td class="c3">2022,2023,2024 </td>
  </tr>
  <tr class="r2">
    <td class="c1">First-Class Scholarship <span class="small-text">(Top 5%)</span>,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2022,2023,2024</td>
  </tr>
</table>

<h2>Misc</h2>
<table id="noborder">
  <tr class="r1">
    <td class="c1">Patent: Energy-saving calculation method,</td>
    <td class="c2"><a href="https://patents.google.com/patent/CN116085952B/en">CN116085952</a>.</td>
    <td class="c3"></td>
  </tr>
<!--   <tr class="r2">
    <td class="c1">Reviewer Service:</td>
    <td class="c2">IEEE Access</td>
    <td class="c3"></td>
  </tr> -->
</table>

<h2>Skills</h2>
<ul>
<li><p>Languages: Python, C/C++, Verilog, MATLAB, LaTex</p>
</li>
<li><p>Tools    : PyTorch, Tensorflow, Vivado, Cadence, VCS</p>
</li>
</ul>
</div>

<div style="width: 100%; text-align: center; padding-top: 20px;">
<a href="https://clustrmaps.com/site/1bzor"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=5NhdhpOXLsoSlWbeGNDzOGrubR9MoMrLGdwO7bcPOIc&cl=ffffff" /></a>
</div>
</body>
</html>
