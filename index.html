<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta name="keywords" content="Yu(Jaray) Li, WHU" />
<meta name="description" content="Jaray Li's Homepage" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="img/intro/whu_logo.png" />
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="css/jemdoc_yuzhe.css" type="text/css" />
<link rel="stylesheet" href="ccs/myMiddle.css" type="text/css" />
<title>Yu Li -- ECE@WHU</title>
</head>
<body>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="img/intro/YuLi_mid.jpg" alt="" width="240px" height="Yu Li" />&nbsp;</td>
<td align="left"><h1>Yu(Jaray) Li <span style="font-family: KaiTi;">李煜</span></h1>
<p><b>Senior Student</b> <br />
<a href="https://hyxt.whu.edu.cn/">Hongyi Honor College</a> <br />
<a href="https://www.whu.edu.cn/">Wuhan University</a> <br />
<!-- <b>Supervisor</b>: <a href="http://www.cse.cuhk.edu.hk/~byu/">Prof. Bei YU</a> <br /> -->
<b>Email</b>:yul79@uci.edu<br /></p>
<p>
  [<a href="https://github.com/skylanding" target="_blank" class="links">Github</a>]
  [<a href="https://www.linkedin.com/in/yu-li-a089a6282/" target="_blank" class="links">Linkedin</a>]
  [<a href="Curriculum_Vitae_of_YuLi.pdf" target="_blank" class="links">CV</a>]
</p>

</td></tr></table>
<h2>Biography</h2>
<p>I am currently a senior in <a href="https://hyxt.whu.edu.cn/">Honyi Honor College</a> of <a href="https://en.whu.edu.cn/">Wuhan University</a>, majoring in Microelectronics Science and Engineering. I have a certain understanding of digital/analog circuits and computer architecture. My current main research direction is the application of AI in vision, including LLM/VLM research.<br /> </p>
<h2>Recent News</h2>
<div class="infoblock">
<div class="blockcontent">
<ul>
<li><p>[08/2024] I am looking for a PhD position for Fall 25 entry, and I hope to continue exploring ML as well as VLM and applications in computer vision.</p>
</li>
<li><p>[05/2024] I will join <a href="https://aicps.eng.uci.edu/">AICPS</a> at UC Irvine as a research intern, during summer 2024.</p>
</li>
<li><p>[05/2024] - I was awarded the <a href="https://edf.whu.edu.cn/chf/zzxm/yngjjljxj/xmjs.htm">Innova International Exchange Scholarship</a>, thanks to Dr. Charles Huang and Charles Huang Foundation!</p>
</li>
</ul>
</div></div>
<!-- <h2>Research Interest</h2>
<ul>
<li><p>VLM/LLM for Computer Vision</p>
</li>
<li><p>AI applications(Medical & EDA) </p>
</li>
</ul> -->
<!-- <h2>Publication</h2>
<ul>
<li><p>[C4] <b>Lancheng Zou</b>, Wenqian Zhao, Shuo Yin, Chen Bai, Qi Sun, Bei Yu, &ldquo;BiE: Bi-Exponent Block Floating-Point for Large Language Models Quantization&rdquo;, International Conference on Machine Learning (ICML), Vienna, Jul. 21–27, 2024.
</p>
</li>
<li><p>[C3] Jiaxi Jiang, <b>Lancheng Zou</b>, Wenqian Zhao, Zhuolun He, Tinghuan Chen, Bei Yu, &ldquo;PDRC: Package Design Rule Checking via GPU-Accelerated Geometric Intersection Algorithms for Non-Manhattan Geometry&rdquo;, Design Automation Conference (DAC), San Francisco, Jun. 23–27, 2024
</p>
</li>
<li><p>[C2] Su Zheng*, <b>Lancheng Zou*</b>, Peng Xu, Siting Liu, Bei Yu, Martin D.F. Wong, &ldquo;Lay-Net: Grafting Netlist Knowledge on Layout-Based Congestion Prediction&rdquo;, International Conference on Computer-Aided Design (ICCAD), San Francisco, Oct. 29–Nov. 02, 2023
</p>
</li>
<li><p>[C1] Su Zheng, <b>Lancheng Zou</b>, Siting Liu, Yibo Lin, Bei Yu, Martin D.F. Wong, &ldquo;Mitigating Distribution Shift for Congestion Optimization in Global Placement&rdquo;, Design Automation Conference (DAC), San Francisco, Jul. 09–13, 2023</p>
</li>
</ul> -->

<h2>Research</h2>
<p>
  My research focuses on ML&AI application, including improvement of LVLM/VLM, application in medical/healthcare field and integration with EDA.
</p>

<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%;">
            <img src="img/project/UCI_fusion.png" width="250" height="180" alt="UCI Fusion Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%;">
            <p>
              Sensor Fusion for Robust and Efficient Autonomous Vehicle Perception
              <br>
              <b>Yu Li</b>, Junyao Wang
              <br>
              2024.6-Present.
              <br>
              [<a href="https://arxiv.org/abs/2201.06644">Baseline</a>]
              [<a href="https://github.com/aimotive/aimotive_dataset">Dataset</a>]
              <br>
              <br>
              Our main work is how to use multi-modal large models to improve the algorithm fusion of weather anomalies in autonomous driving mode.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

    
<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Ultrasound.jpg" width="250" height="180" alt="Ultrasound Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
              <papertitle>
              Ultrasound image segmentation based on SAM and Transformer multi-level feature fusion
              </papertitle>
              <!-- </a> -->
              <br />
              <b>Yu Li</b>, Jin Huang
              <br />
              2023.10-2024.5
              <br />
              Under Review, <em>IEEE Journal of Biomedical and Health Informatics.</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding/DSATNet">Code</a>]
            </div>
            <br>
            <p>
              We leveraged the rich semantic segmentation information of SAM and 
              applied its fine-grained attention capability to the feature extraction module of Transformer, 
              achieving SOTA IoU scores in ultrasound image segmentation.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Ultrasound2.jpg" width="250" height="180" alt="Ultrasound Image 2"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
                <papertitle>
                  Windowed self-attention guided multi-scale feature stream alignment network for ultrasound image segmentation
                </papertitle>
              <!-- </a> -->
              <br />
              Jin Huang, Xiaoxiao Li, <strong>Yu Li</strong>
              <br />
              2023.9-2024.5
              <br />
              Under Review, <em>Biomedical Signal Processing and Control.</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding">Code</a>]
            </div>
            <br>
            <p>
              We explored the self-attention guidance mechanism of the Swin-Transformer structure in breast ultrasound images, 
              used a multi-level encoder to deal with multi-dimensional features, 
              and used spatial pyramid pooling and feature stream alignment to fuse shallow and deep information.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Depth.jpg" width="250" height="180" alt="Depth Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
                <papertitle>
                  Diffusion model with discriminative priors: Self-supervised monocular depth estimation in endoscopy
                </papertitle>
              <!-- </a> -->
              <br />
              <strong>Yu Li</strong>
              <br />
              2024.2-2024.6
              <br />
              Under Review, <em> International Journal of Computer Assisted Radiology and Surgery.</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding">Code</a>]
            </div>
            <br>
            <p>
            For endoscope medical scenarios, we use the diffusion model for depth estimation. We build a teacher model, set knowledge distillation, 
            optical appearance and ddim losses, and introduce the teacher's discriminative prior, which significantly enhances the accuracy and confidence of the results.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Monte.png" width="250" height="180" alt="Monte Carlo Simulation Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
                <papertitle>
                SpO2 measurement model based on Monte Carlo simulation
                </papertitle>
              <!-- </a> -->
              <br />
              <strong>Yu Li</strong>, Shing-jiuan Liu, Prof. Weijian Yang
              <br />
              2023.7-2024.5
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding/oximetrey-model">Code</a>]
            </div>
            <br>
            <p>
            We used the modified Beer-Lambert law for reverse deduction, used Monte Carlo simulation data to improve the SpO2 measurement process model and design algorithms, 
            and finally realized the reverse model for determining physiological parameters from simulation data.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/ECG.jpg" width="250" height="180" alt="ECG Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <papertitle>
              ECG classification based on deep learning
              </papertitle>
              <br />
              <strong>Yu Li</strong>, Yunhao Hu
              <br />
              2022.10-2023.3
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://ieeexplore.ieee.org/abstract/document/10335476?casa_token=W35SppfudKkAAAAA:7FrTtfe0OgPMGoRX79ruUt9Ryqpa2Bqnpm2rnvq5MJzDpCw7z8bd9Gfww7SCVQBLez37qyKiYDY">Paper</a>]
            [<a href="https://github.com/Skylanding/ECG-Classification">Code</a>]
            </div>
            <br>
            <p>
              For the attempt of deep learning method for ECG classification, 
              the construction of multi-layer neural network and the parameter grid search of effective tool XGBoost.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<h3>Projects</h3>
<p>
  Individual or Collaborative Projects
</p>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: top">
        <img src="img/project/Dlora.png" width="250" height="180" alt="DLoRA module"/>
      </td>
      <td class="tdcontent" style="padding: 20px; width: 65%; vertical-align: top">
        <p>
          <a href="https://arxiv.org/abs/2404.12734">
            <papertitle>
              <b>DLoRA-TrOCR: Mixed Text Mode Optical Character Recognition Based On Transformer.</b>
            </papertitle>
          </a>
          <br />
          <b>Yu Li</b>& Da Chang</a>
          <br />
          2024.4,<em>Under submission</em>.
        </p>
        <div class="paper" id="xu2020batchnorm">
          [<a href="https://arxiv.org/abs/2404.12734">Paper</a>]
          [<a href="https://github.com/VceChang/DLoRA-TrOCR">Code</a>]
        </div>
        <br>
        We explored the optimization of various full-parameter fine-tuning methods such as LoRA in LLM. For OCR, a hybrid visual-text model, corresponding to the Transformer architecture, DoRA and LoRA have good improvement effects on the visual encoder and text decoder respectively.
        </p>
      </td>
    </tr>
    
    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
        <img src="img/project/EECS151.png" width="250" height="180" alt="UCB eecs151 aisc"/>
      </td>
      <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: top">
        <p>
          <a href="https://github.com/Skylanding/EECS151-Project">
            <papertitle>
              <b>A 3-stage CPU that implements the RISC-V ISA.</b> [UCB EECS151 Project]
            </papertitle>
          </a>
          <br />
          <b>Yu Li</b>, Timonty Chu
          <br />
          2024.2-2024.4
          <br />
        </p>
        <div class="paper" id="xu2020batchnorm">
          [<a href="https://github.com/EECS150/asic-project-sp24">Asic Lab</a>]
          [<a href="data/pdf/riscv-spec-20191213.pdf">Manual</a>]
          [<a href="https://github.com/Skylanding/EECS151-Project">Project</a>]
        </div>
        <br>
        <p>
          In the first phase (front-end), I design and implement a 3-stage RISC-V processor in Verilog, 
          and run simulations to test for functionality.
          Then in the second phase (back-end), I implement front-end design in the SKY130 PDK using the VLSI tools.
        </p>
      </td>
    </tr>

    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
        <img src="img/project/EE140.png" width="250" height="180" alt="UCB ee140 project"/>
      </td>
      <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
        <p>
          <a href="https://github.com/Skylanding/2024_spring_ee140">
          <papertitle>
          <b>LCD Driver Design: 2-Stage Operational Amplifier. </b> [UCB EE140 Project] 
          </papertitle>
          </a>
          <br />
          <b>Yu Li</b>
          <br />
          2024.2-2024.4
          <br />
        </p>
        <div class="paper" id="xu2020batchnorm">
        [<a href="https://github.com/Skylanding/24-spring-ee140/blob/main/lab/project/LCD%20Driver%20Project.pdf">Project</a>]
        [<a href="data/pdf/EE140_project.pdf">Report</a>]
        </div>
        <br>
        <p>
          To use a series resistance of 400 Ohms and a capacitance of 60 pF to design the LCD amplifier to the specifications.
        </p>
      </td>
    </tr>

    <tr>
      <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
        <img src="img/project/Unisoc.png" width="250" height="180" alt="Unisoc Competition"/>
      </td>
      <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
        <p>
          <!-- <a href="https://github.com/Skylanding/EECS151-Project"> -->
            <papertitle>
              FPGA-based video acquisition and performance acceleration
            </papertitle>
          <!-- </a> -->
          <br />
          <b>Yu Li</b>
          <br />
          2023.3-2023.6
          <br />
        </p>
        <div class="paper" id="xu2020batchnorm">
        [<a href="http://univ.ciciec.com/nd.jsp?id=556">Competition Link</a>]
        </div>
        <br>
        <p>
          A multi-channel video acquisition and acceleration system was implemented through Unisoc FPGA. 
          It includes video input collection of two different transmission methods, HDMI/PCIE, onboard DDR video frame buffer, 
          video output of HDMI/PCIE two methods, video splicing, scaling and other functions.
        </p>
      </td>
    </tr>
  </tbody>
</table>


<h2>Education</h2>
<ul>
<!-- <li><p>Ph.D., Department of Computer Science and Engineering, The Chinese University of Hong Kong (CUHK), Aug/2023 - Now</p>
</li> -->
<li><p>B.Eng., Hongyi Honor College, Wuhan University (WHU), Aug/2021 - Jun/2025</p>
</li>
</ul>
<h2>Experiences</h2>
<ul>
  <li><b><a href="https://aicps.eng.uci.edu/">Research Intern</a></b>, UC Irvine, Summer 2024.</li>
</ul>
<ul>
  <li><b><a href="https://eecs.berkeley.edu/">Visiting Student</a></b>, UC Berkeley, Spring 2024.</li>
</ul>
<ul>
  <li><b><a href="https://www.ece.ucdavis.edu/~wejyang/home.html">Research Intern</a></b>, UC Davis, 2023-2024.</li>
</ul>
<ul>
  <li><b><a href="http://www.lei-whu.com/">Research Assistant</a></b>, WHU, 2022-2024.</li>
</ul>
<h2>Honors and Awards</h2>
<table id="noborder">
  <tr class="r1">
    <td class="c1">Innova International Exchange Scholarship,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2024</td>
  </tr>
  <tr class="r2">
    <td class="c1">Innova Excellence Scholarship <span class="small-text">(Top 3%)</span>,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2023</td>
  </tr>
  <tr class="r1">
    <td class="c1">Academic Excellence Scholarship <span class="small-text">(Top 5%)</span>,</td>
    <td class="c2">Hongyi Honor College,</td>
    <td class="c3">2022</td>
  </tr>
  <tr class="r2">
    <td class="c1">First-Class Scholarship <span class="small-text">(Top 5%)</span>,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2022 & 2023</td>
  </tr>
</table>

<h2>Misc</h2>
<table id="noborder">
  <tr class="r1">
    <td class="c1">National Invention Patent: Energy-saving calculation method,</td>
    <td class="c2"><a href="https://patents.google.com/patent/CN116085952B/en">CN116085952</a>,</td>
    <td class="c3"></td>
  </tr>
</table>

<h2>Skills</h2>
<ul>
<li><p>Languages: Python, C/C++, Verilog, MATLAB, LaTex</p>
</li>
<li><p>Tools    : PyTorch, Tensorflow, Vivado, Cadence, VCS</p>
</li>
</ul>
</div>
<a title="web analytics" href="http://statcounter.com/"target="_blank"><img
src="//c.statcounter.com/12906289/0/be08a441/0/" alt="web
analytics" style="border:none;"></a>
</body>
</html>
