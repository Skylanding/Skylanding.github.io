<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta name="keywords" content="Yu Li, WHU" />
<meta name="description" content="Yu Li's Homepage" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="img/intro/gw_logo.png" />
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="css/jemdoc_yuzhe.css" type="text/css" />
<link rel="stylesheet" href="ccs/myMiddle.css" type="text/css" />
<title>Yu Li @ECE.GWU</title>
</head>
<body>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="img/intro/YuLi_mid.jpg" alt="" width="240px" height="Yu Li" />&nbsp;</td>
<td align="left"><h1>Yu Li <span style="font-family: KaiTi;">李煜</span></h1>
<p><b>Senior Student</b> <br />
<a href="https://hyxt.whu.edu.cn/">Hongyi Honor College</a> <br />
<a href="https://en.whu.edu.cn/">Wuhan University</a> <br />

<b>Email</b>:yul@gwu.edu / yuuli2021@whu.edu.cn <br /></p>
<p>
  [<a href="https://github.com/skylanding" target="_blank" class="links">Github</a>]
  [<a href="https://www.linkedin.com/in/yu-li-a089a6282/" target="_blank" class="links">Linkedin</a>]
  [<a href="CV_Yu_Li_25.pdf" target="_blank" class="links">CV</a>]
  [<a href="https://scholar.google.com/citations?user=EjGk0dwAAAAJ&hl=en" target="_blank" class="links">Google Scholar</a>]
</p>

</td></tr></table>
<h2>Biography</h2>
<p>I am currently a senior student in <a href="https://hyxt.whu.edu.cn/">Hongyi Honor College</a> of <a href="https://en.whu.edu.cn/">Wuhan University</a>, specializing in digital/analog circuits and embedded development. My current research focuses on generative AI and RL agents.<br /> </p>
<h2>Recent News</h2>
<div class="infoblock">
<div class="blockcontent">
<ul>
<li><p>[04/2025] I will be pursuing my ECE PhD supervised by Prof.Tian Lan at GWU. I will mainly explore RL and LLM aspects.</p>
</li>
<li><p>[03/2025] I will join the AGI Lab for a pre-graduation intern, mainly focusing on generative models.</p>
</li>
<li><p>[08/2024] I was awarded the Innova Excellence Scholarship, top 3% in our college.</p>
</li>
<li><p>[05/2024] I was awarded the <a href="https://edf.whu.edu.cn/chf/zzxm/yngjjljxj/xmjs.htm">Innova International Exchange Scholarship</a>, thanks to Dr. Charles Huang and Charles Huang Foundation!</p>
</li>
</ul>
</div></div>


<h2>Selected Projects</h2>
<p>
I had a wide range of research interests during my undergraduate years.At the moment I'm mainly exploring generative AI and LLMs optimization methods.
</p>


<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%;">
            <img src="img/project/alpha.jpg" width="250" height="180" alt="Alpha"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%;">
            <p>
              AlphaAdam:Asynchronous Masked Optimization with Dynamic Alpha for Selective Updates
              <br>
              Da Chang, <b>Yu Li</b>, Ganzhao Yuan
              <br/>
              2025.1
              <br/>
              <em>Preprint</em>
              <br/>
              [<a href="https://arxiv.org/pdf/2501.18094">Paper</a>]
              <br>
              Developed AlphaAdam, an LLM optimization framework using intra-layer parameter updates. Created parameter masks based on historical momentum and gradient consistency, paired with adaptive mask strength for efficient optimization and guaranteed convergence. 
		    Outperformed AdamW in convergence speed and efficiency across GPT-2, RoBERTa, and Llama-7B tasks.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

  
<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%;">
            <img src="img/project/UCI_fusion.png" width="250" height="180" alt="UCI Fusion Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%;">
            <p>
              Sensor Fusion for Robust and Efficient Autonomous Vehicle Perception
              <br>
              <b>Yu Li</b>, Junyao Wang
              <br/>
              2024.6-2024.10
              <br/>
              Submitted to <em>ICCV 2025</em>
              <br/>
              [<a href="https://github.com/Skylanding/SensorFusion">Code</a>]
              <br>
              <br>
              Our main work is to construct our VLM to improve the autonomous driving mode in abnormal weather conditions, focusing on improving the multi-modal fusion algorithm of Camera-Lidar branches.
              Hopefully it will be advanced to hardware deployment in the future.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

    
<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Ultrasound.jpg" width="250" height="180" alt="Ultrasound Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <a href="https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.17751">
              <papertitle>
              Ultrasound image segmentation based on SAM and Transformer multi-level feature fusion
              </papertitle>
              </a>
              <br />
              <b>Yu Li</b>, Jin Huang
              <br />
              2023.10-2024.5
              <br />
              <em>Medical Physics</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding/DSATNet">Code</a>]
            </div>
            <br>
            <p>
              We leveraged the rich semantic segmentation information of SAM and 
              applied its fine-grained attention capability to the feature extraction module of Transformer, 
              achieving SOTA IoU scores in ultrasound image segmentation.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Ultrasound2.jpg" width="250" height="180" alt="Ultrasound Image 2"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <!-- <a href="https://arxiv.org/abs/2404.12734"> -->
                <papertitle>
                  Windowed self-attention guided multi-scale feature stream alignment network for ultrasound image segmentation
                </papertitle>
              <!-- </a> -->
              <br />
              Jin Huang, Xiaoxiao Li, <strong>Yu Li</strong>
              <br />
              2023.9-2024.5
              <br />
              Under Review, <em>Biomedical Signal Processing and Control.</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding">Code</a>]
            </div>
            <br>
            <p>
              We explored the self-attention guidance mechanism of the Swin-Transformer structure in breast ultrasound images, 
              used a multi-level encoder to deal with multi-dimensional features, 
              and used spatial pyramid pooling and feature stream alignment to fuse shallow and deep information.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<div class="research-block">
  <div class="research-content">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td class="tdimg" style="padding: 16px; width: 35%; vertical-align: center">
            <img src="img/project/Depth.jpg" width="250" height="180" alt="Depth Image"/>
          </td>
          <td class="tdcontent" style="padding: 16px; width: 65%; vertical-align: center">
            <p>
              <a href="https://link.springer.com/article/10.1007/s11548-025-03333-0">
                <papertitle>
                Diffusion model with discriminative priors: Self-supervised monocular depth estimation in endoscopy
                </papertitle>
              </a>
              <br />
              <strong>Yu Li</strong>
              <br />
              2024.2-2024.6
              <br />
              Accept, <em> International Journal of Computer Assisted Radiology and Surgery.</em>
              <br />
            </p>
            <div class="paper" id="xu2020batchnorm">
            [<a href="https://github.com/Skylanding">Code</a>]
            </div>
            <br>
            <p>
            For endoscope medical scenarios, we use the diffusion model for depth estimation. We build a teacher model, set knowledge distillation, 
            optical appearance and ddim losses, and introduce the teacher's discriminative prior, which significantly enhances the accuracy and confidence of the results.
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<h2>Education</h2>
<ul>
<li><p>Ph.D., Electrical and Computer Engineering, George Washington University (GWU), Sep/2025 - Jun/2030 (expected)</p>
</li>
<li><p>B.Eng., Hongyi Honor College, Wuhan University, Aug/2021 - Jun/2025</p>
</li>
</ul>
<h2>Experience</h2>
<ul>
  <li><b><a href="https://icoz69.github.io/">Research Intern</a></b>, Westlake University, 2025.</li>
</ul>
<ul>
  <li><b><a href="https://aicps.eng.uci.edu/">Research Intern</a></b>, UC Irvine, Summer 2024.</li>
</ul>
<ul>
  <li><b><a href="https://eecs.berkeley.edu/">Visiting Student</a></b>, UC Berkeley, Spring 2024.</li>
</ul>
<ul>
  <li><b><a href="https://www.ece.ucdavis.edu/~wejyang/home.html">Research Intern</a></b>, UC Davis, 2023-2024.</li>
</ul>
<ul>
  <li><b><a href="http://www.lei-whu.com/">Research Assistant</a></b>, WHU, 2022-2024.</li>
</ul>
<h2>Honors and Awards</h2>
<table id="noborder">
  <tr class="r1">
    <td class="c1">Innova International Exchange Scholarship,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2024</td>
  </tr>
  <tr class="r2">
    <td class="c1">Innova Excellence Scholarship <span class="small-text">(Top 3%)</span>,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2023,2024</td>
  </tr>
  <tr class="r1">
    <td class="c1">Academic Excellence Scholarship <span class="small-text">(Top 5%)</span>,</td>
    <td class="c2">Hongyi Honor College,</td>
    <td class="c3">2022,2023,2024 </td>
  </tr>
  <tr class="r2">
    <td class="c1">First-Class Scholarship <span class="small-text">(Top 5%)</span>,</td>
    <td class="c2">Wuhan University,</td>
    <td class="c3">2022,2023,2024</td>
  </tr>
</table>

<h2>Misc</h2>
<table id="noborder">
  <tr class="r1">
    <td class="c1">Patent: Energy-saving calculation method,</td>
    <td class="c2"><a href="https://patents.google.com/patent/CN116085952B/en">CN116085952</a>.</td>
    <td class="c3"></td>
  </tr>
  <tr class="r2">
    <td class="c1">Journal/conference review services:</td>
    <td class="c2">MICCAI 2025, ICCV 2025, IEEE Access</td>
    <td class="c3"></td>
  </tr>
</table>

<h2>Skills</h2>
<ul>
<li><p>Languages: Python, C/C++, Verilog, MATLAB, LaTex</p>
</li>
<li><p>Tools: PyTorch, Tensorflow, Vivado, Cadence, VCS</p>
</li>
</ul>
</div>

<div style="width: 100%; text-align: center; padding-top: 20px;">
<a href="https://clustrmaps.com/site/1bzor"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=5NhdhpOXLsoSlWbeGNDzOGrubR9MoMrLGdwO7bcPOIc&cl=ffffff" /></a>
</div>
</body>
</html>
